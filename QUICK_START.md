# 快速开始指南（30分钟理解核心）

## 🎯 目标
30分钟内理解 RAG 系统的核心流程，能向面试官解释。

## ⚡ 三步走

### 第一步：运行简化示例（5分钟）

```bash
go run examples/simple/main.go
```

**看什么**：
- 系统如何初始化
- 如何添加文档
- 如何查询

**理解什么**：
- RAG = 检索 + 生成
- 先找文档，再生成回答

### 第二步：看核心代码（15分钟）

只看这 1 个文件：`internal/rag/rag.go`

**重点看 `Query` 方法**，这是整个系统的核心：

```go
// 1. 检索相关文档
results, err := r.retrieverService.Retrieve(ctx, query, topK)

// 2. 构建上下文（把文档内容组合起来）
context := strings.Join(contextParts, "\n\n")

// 3. 构建提示词（问题和文档组合）
promptText := r.promptService.BuildPrompt(context, query)

// 4. 生成回答
answer, err := r.llmService.Generate(ctx, messages)
```

**理解流程**：
```
问题 → 找文档 → 组合提示词 → 生成回答
```

### 第三步：画流程图（10分钟）

在纸上画这个：

```
用户: "什么是 Go？"
  ↓
[向量化问题]
  ↓
[在文档库中找最相似的文档]
  ↓
[把文档内容提取出来]
  ↓
[组合成提示词: "Context: ... Question: 什么是 Go？"]
  ↓
[调用 LLM]
  ↓
[返回回答]
```

## 💬 面试时怎么说（2分钟版本）

**开场**：
"我学习 RAG 系统，用 Go 实现了一个最小版本。RAG 的核心思想是：先检索相关文档，再基于文档生成回答，这样比直接问 LLM 更准确。"

**技术要点**：
1. **向量化**：把文本变成数字向量，方便计算相似度
2. **检索**：用余弦相似度找最相关的文档
3. **增强**：把文档作为上下文给 LLM
4. **生成**：LLM 基于真实文档生成回答

**项目亮点**：
- 完整的 RAG 流程实现
- 模块化设计，易于扩展
- 使用 Go + Gin，性能好

**改进方向**：
- 使用向量数据库（Qdrant）
- 集成真实 LLM（OpenAI）
- 添加缓存和监控

## 📚 深入学习路径

1. **今天**：理解核心流程（看 `rag.go`）
2. **明天**：理解每个模块的作用（看 `LEARNING_GUIDE.md`）
3. **后天**：运行和调试（修改代码看效果）
4. **面试前**：准备技术问题和回答（看 `ARCHITECTURE.md`）

## ❓ 常见问题速答

**Q: RAG 是什么？**
A: 检索增强生成。先检索相关文档，再基于文档生成回答。

**Q: 为什么需要 RAG？**
A: LLM 知识有限，可能产生幻觉。RAG 让 LLM 基于真实文档回答，更准确。

**Q: 向量是什么？**
A: 一串数字，比如 [0.1, 0.5, 0.3]。相似文本的向量也相似。

**Q: 余弦相似度是什么？**
A: 计算两个向量相似程度的方法。值越大越相似。

**Q: 这个项目能用于生产吗？**
A: 不能。这是学习版本。生产需要向量数据库、真实 LLM、缓存等。

## ✅ 检查清单

- [ ] 能说出 RAG 是什么
- [ ] 能画出核心流程图
- [ ] 能解释 `Query` 方法的 4 个步骤
- [ ] 能运行 `simple_example.go`
- [ ] 能向别人解释这个项目

## 🆘 遇到问题？

1. **代码看不懂** → 先看 `examples/simple/main.go`，它最简单
2. **概念不理解** → 看 `LEARNING_GUIDE.md` 的"常见困惑"部分
3. **运行出错** → 检查 Go 版本，确保是 1.21+

记住：**理解流程比理解所有细节更重要！**

