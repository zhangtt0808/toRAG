# RAG 系统学习指南

## 🎯 学习目标
作为 Go 后端工程师，通过这个项目学习 RAG 系统，准备 AI 应用开发工程师面试。

## 📚 学习路径（从简单到复杂）

### 阶段 1: 理解 RAG 核心概念（1-2天）
**目标**: 理解 RAG 是什么，为什么需要它

1. **什么是 RAG？**
   - RAG = Retrieval-Augmented Generation（检索增强生成）
   - 简单理解：先检索相关文档，再基于文档生成回答
   - 类比：就像考试时先查资料，再写答案

2. **RAG 的流程**
   ```
   用户问题 → 向量化 → 检索相似文档 → 构建提示词 → LLM 生成回答
   ```

3. **为什么需要 RAG？**
   - LLM 的知识有截止日期
   - LLM 可能产生幻觉（编造信息）
   - RAG 让 LLM 基于真实文档回答，更准确

### 阶段 2: 理解项目结构（2-3天）
**目标**: 理解每个模块的作用

#### 核心模块（按学习顺序）

1. **Prompt 模块** (`internal/prompt/`) - ⭐ 最简单，先看这个
   - **作用**: 把用户问题和检索到的文档组合成提示词
   - **类比**: 就像写作文的模板
   - **关键代码**: `prompt.go` 的 `BuildPrompt` 方法

2. **LLM 模块** (`internal/llm/`) - ⭐ 第二简单
   - **作用**: 调用大语言模型生成回答
   - **类比**: 就像调用 API
   - **关键代码**: `mock.go` 的 `Generate` 方法

3. **Embedding 模块** (`internal/embedding/`) - ⭐⭐ 中等难度
   - **作用**: 把文本转换成数字向量
   - **类比**: 就像把文字翻译成坐标
   - **关键代码**: `simple.go` 的 `EmbedText` 方法
   - **核心概念**: 向量 = 一串数字，相似文本的向量也相似

4. **Retriever 模块** (`internal/retriever/`) - ⭐⭐ 中等难度
   - **作用**: 根据问题找到最相关的文档
   - **类比**: 就像搜索引擎
   - **关键代码**: `memory.go` 的 `Retrieve` 方法
   - **核心概念**: 余弦相似度 = 计算两个向量的相似程度

5. **Ranker 模块** (`internal/ranker/`) - ⭐⭐⭐ 可选，先跳过
   - **作用**: 对检索结果排序
   - **类比**: 就像搜索结果排序
   - **可以先不看**: 简单版本已经够用

6. **RAG 核心服务** (`internal/rag/`) - ⭐⭐⭐ 整合所有模块
   - **作用**: 把上面所有模块组合起来
   - **关键代码**: `rag.go` 的 `Query` 方法
   - **这是最重要的文件！**

### 阶段 3: 运行和调试（1-2天）
**目标**: 让系统跑起来，理解数据流

1. **运行示例程序**
   ```bash
   # 简化示例（推荐先看这个）
   go run examples/simple/main.go
   
   # 完整示例
   go run examples/example.go
   ```
   - 看输出，理解每一步做了什么
   - 在关键位置加 `fmt.Println` 打印中间结果

2. **运行服务器**
   ```bash
   go run cmd/server/main.go
   ```
   - 用 Postman 或 curl 测试 API
   - 观察日志输出

3. **修改代码实验**
   - 修改 `SimpleEmbedder` 的维度，看效果
   - 修改 `MockLLM` 的回复，看输出变化
   - 添加更多文档，测试检索效果

### 阶段 4: 深入理解（3-5天）
**目标**: 理解实现细节，能解释给面试官听

1. **向量化原理**
   - 为什么用词频？
   - 为什么需要归一化？
   - 余弦相似度怎么计算？

2. **检索原理**
   - 为什么用余弦相似度？
   - Top-K 检索是什么意思？

3. **提示词工程**
   - 为什么要把文档放在提示词里？
   - 不同的提示词模板有什么区别？

### 阶段 5: 面试准备（2-3天）
**目标**: 能清晰地向面试官解释项目

1. **准备项目介绍（2分钟）**
   - 项目背景：学习 RAG，准备转 AI 应用开发
   - 技术选型：Go + Gin + 内存存储
   - 核心功能：文档检索 + LLM 生成

2. **准备技术问题**
   - RAG 的原理是什么？
   - 向量检索是怎么工作的？
   - 如何优化检索效果？
   - 如何扩展到生产环境？

3. **准备代码讲解**
   - 能画出系统架构图
   - 能解释关键代码片段
   - 能说出改进方向

## 🚀 快速开始（今天就能理解）

### 第一步：只看这 3 个文件（30分钟）

1. **`internal/rag/rag.go`** - 看 `Query` 方法
   - 这是整个系统的核心流程
   - 理解：检索 → 构建提示 → 生成回答

2. **`examples/example.go`** - 看完整示例
   - 看如何初始化服务
   - 看如何添加文档和查询

3. **`cmd/server/main.go`** - 看服务启动
   - 看如何组装各个模块

### 第二步：运行示例（10分钟）
```bash
go run examples/example.go
```
观察输出，理解每一步。

### 第三步：画流程图（20分钟）
在纸上画出：
- 用户提问 → 系统做了什么 → 返回答案

## 💡 面试重点（记住这些就够了）

### 1. RAG 的核心价值
- **问题**: LLM 知识有限，可能产生幻觉
- **解决**: 基于真实文档生成回答
- **效果**: 更准确、可追溯

### 2. 技术栈选择
- **Go**: 高性能、并发友好
- **内存存储**: 简单、快速原型
- **Gin**: 轻量级 Web 框架

### 3. 系统架构
```
用户请求 → API 层 → RAG 服务 → [检索 + 生成] → 返回结果
```

### 4. 关键技术点
- **向量化**: 文本 → 数字向量
- **相似度计算**: 余弦相似度
- **提示词工程**: 如何组织上下文

### 5. 改进方向（面试加分）
- 使用向量数据库（Qdrant、Pinecone）
- 集成真实 LLM（OpenAI、Claude）
- 添加缓存机制
- 支持多模态（图片、PDF）

## 📖 推荐学习资源

1. **RAG 概念**: 
   - 搜索 "RAG retrieval augmented generation" 
   - 看 LangChain 的 RAG 教程

2. **向量检索**:
   - 搜索 "vector similarity search"
   - 理解余弦相似度

3. **Go 并发**:
   - 如果要用到并发优化，看 Go 的 goroutine

## ⚠️ 常见困惑

### Q: 向量是什么？
A: 一串数字，比如 [0.1, 0.5, 0.3, ...]。相似文本的向量也相似。

### Q: 为什么用余弦相似度？
A: 它只关注方向，不关注大小，适合文本相似度。

### Q: Embedding 和 Retriever 的区别？
A: Embedding 负责"翻译"（文本→向量），Retriever 负责"查找"（找相似向量）。

### Q: 这个项目能直接用于生产吗？
A: 不能。这是学习版本，生产需要：
- 向量数据库
- 真实 LLM API
- 错误处理
- 性能优化

## 🎯 学习检查清单

- [ ] 能说出 RAG 是什么
- [ ] 能画出系统流程图
- [ ] 能解释每个模块的作用
- [ ] 能运行示例程序
- [ ] 能修改代码并看到效果
- [ ] 能向别人解释这个项目
- [ ] 知道如何改进这个系统

## 📞 遇到问题？

1. **代码看不懂**: 先看 `examples/example.go`，它最简单
2. **概念不理解**: 搜索相关概念，看 Wikipedia
3. **运行出错**: 检查 Go 版本，确保依赖已安装

记住：**理解核心流程比理解所有细节更重要！**

